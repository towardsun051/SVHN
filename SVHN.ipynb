{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' #用于避免jupyter环境突然关闭\n",
    "torch.backends.cudnn.benchmark=True #用于加速GPU运算的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as m\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1412)\n",
    "random.seed(1412)\n",
    "np.random.seed(1412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.SVHN(root ='D:\\study\\ML\\kaggle\\SVHN\\dataset'\n",
    "                                  ,split =\"train\"\n",
    "                                  ,download = True\n",
    "                                    #,transform = T.ToTensor()\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.SVHN(root ='D:\\study\\ML\\kaggle\\SVHN\\dataset'\n",
    "                                  ,split =\"train\"\n",
    "                                  ,download = False\n",
    "                                  ,transform = T.ToTensor()\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torchvision.datasets.SVHN(root ='D:\\study\\ML\\kaggle\\SVHN\\dataset'\n",
    "                                ,split =\"test\"\n",
    "                                ,download = True\n",
    "                                ,transform = T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotsample(data):\n",
    "    fig, axs = plt.subplots(1,5,figsize=(10,10)) #建立子图\n",
    "    for i in range(5):\n",
    "        num = random.randint(0,len(data)-1) #首先选取随机数，随机选取五次\n",
    "        #而展示图像用的imshow函数最常见的输入格式也是3通道\n",
    "        npimg = torchvision.utils.make_grid(data[num][0]).numpy()\n",
    "        nplabel = data[num][1] #提取标签\n",
    "        #将图像由(3, weight, height)转化为(weight, height, 3)，并放入imshow函数中读取\n",
    "        axs[i].imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        axs[i].set_title(nplabel) #给每个子图加上标签\n",
    "        axs[i].axis(\"off\") #消除每个子图的坐标轴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotsample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainT = T.Compose([T.RandomCrop(28) #沿用Fashion-MNIST的风格，决定使用28x28的尺寸\n",
    "                    # ,T.RandomRotation(degrees=[-30,30])\n",
    "                    ,T.ToTensor()\n",
    "                    ,T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224,0.225])]\n",
    "                    #由于是实拍数据集，使用ImageNet的方差和偏差进行归一化\n",
    "                    #也可以尝试MNIST数据集的数值\n",
    "                    )\n",
    "testT = T.Compose([T.CenterCrop(28) #测试集不需要数据增强，因此使用CenterCrop\n",
    "                    ,T.ToTensor()\n",
    "                    ,T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224,\n",
    "                    0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.SVHN(root ='D:\\study\\ML\\kaggle\\SVHN\\dataset'\n",
    "                                    ,split =\"train\"\n",
    "                                    ,download = False\n",
    "                                    ,transform = trainT\n",
    "                                    )\n",
    "test = torchvision.datasets.SVHN(root ='D:\\study\\ML\\kaggle\\SVHN\\dataset'\n",
    "                                    ,split =\"test\"\n",
    "                                    ,download = False\n",
    "                                    ,transform = testT\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotsample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1412)\n",
    "resnet18_ = m.resnet18()\n",
    "vgg16_ = m.vgg16() #VGG本来参数量就很大，因此我个人较少使用vgg16_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_.bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_.layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_.layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 =nn.Sequential(nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        ,resnet18_.bn1\n",
    "        ,resnet18_.relu) #删除池化层\n",
    "        #后续的架构直接从经典架构中选\n",
    "        #对尺寸很小的数据集而言，我们的深度本来就不深，因此可以试着在特征图数量上有所增加（增加宽度）\n",
    "        self.block2 = resnet18_.layer2\n",
    "        self.block3 = resnet18_.layer3\n",
    "        #自适应平均池化+线性层，此处都与残差网络一致\n",
    "        self.avgpool = resnet18_.avgpool\n",
    "        #输出的线性层自己写，以确保输出的类别数量正确\n",
    "        self.fc = nn.Linear(in_features=256, out_features=10, bias=True)\n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],256)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[*vgg16_.features[0:9]] #星号用于解码\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[*vgg16_.classifier[1:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVgg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(*vgg16_.features[0:9] #星号用于解码\n",
    "        ,nn.Conv2d(128, 128, kernel_size=3,\n",
    "        stride=1, padding=1)\n",
    "        ,nn.ReLU(inplace=True)\n",
    "        ,nn.MaxPool2d(2,2, padding=0, dilation=1,\n",
    "        ceil_mode=False))\n",
    "        #进入线性层时输入通道数发生变化，因此线性层需要重写\n",
    "        #输出层也需要重写\n",
    "        self.avgpool = vgg16_.avgpool\n",
    "        self.fc = nn.Sequential(nn.Linear(7*7*128, out_features=4096,bias=True)\n",
    "        ,*vgg16_.classifier[1:6]\n",
    "        ,nn.Linear(in_features=4096,\n",
    "        out_features=10,bias=True))\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],7*7*128)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(MyResNet(),(10,3,28,28),depth=1,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(MyVgg(),(10,3,28,28),depth=1,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IterOnce(net,criterion,opt,x,y):\n",
    "    sigma = net.forward(x)\n",
    "    loss = criterion(sigma,y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad(set_to_none=True) #比起设置梯度为0，让梯度为None会更节约内存\n",
    "    yhat = torch.max(sigma,1)[1]\n",
    "    correct = torch.sum(yhat == y)\n",
    "    return correct,loss\n",
    "def TestOnce(net,criterion,x,y):\n",
    "\n",
    "    #对测试，一定要阻止计算图追踪\n",
    "    #这样可以节省很多内存，加速运算\n",
    "    with torch.no_grad():\n",
    "        sigma = net.forward(x)\n",
    "        loss = criterion(sigma,y)\n",
    "        yhat = torch.max(sigma,1)[1]\n",
    "        correct = torch.sum(yhat == y)\n",
    "    return correct,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, tol=0.0005):\n",
    "        self.patience = patience\n",
    "        self.tol = tol\n",
    "        self.counter = 0\n",
    "        self.lowest_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.lowest_loss == None:\n",
    "            self.lowest_loss = val_loss\n",
    "        elif self.lowest_loss - val_loss > self.tol:\n",
    "            self.lowest_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif self.lowest_loss - val_loss < self.tol:\n",
    "            self.counter += 1\n",
    "            print(\"\\t NOTICE: Early stopping counter {} of {}\".format(self.counter,self.patience))\n",
    "        if self.counter >= self.patience:\n",
    "            print('\\t NOTICE: Early Stopping Actived')\n",
    "            self.early_stop = True\n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_test(net,batchdata,testdata,criterion,opt,epochs,tol,modelname,PATH):\n",
    "    SamplePerEpoch = batchdata.dataset.__len__()\n",
    "    allsamples = SamplePerEpoch*epochs\n",
    "    trainedsamples = 0\n",
    "    trainlosslist = []\n",
    "    testlosslist = []\n",
    "    early_stopping = EarlyStopping(tol=tol)\n",
    "    highestacc = None\n",
    "    for epoch in range(1,epochs+1):\n",
    "        net.train()\n",
    "        correct_train = 0\n",
    "        loss_train = 0\n",
    "        for batch_idx, (x, y) in enumerate(batchdata):\n",
    "            y = y.view(x.shape[0])\n",
    "            correct,loss = IterOnce(net,criterion,opt,x,y)\n",
    "            #计算样本总量、总的correct与loss\n",
    "            trainedsamples += x.shape[0]\n",
    "            correct_train += correct\n",
    "            loss_train += loss\n",
    "            if (batch_idx+1) % 125 == 0:\n",
    "                print('Epoch{}:[{}/{}({:.0f}%)]'.format(epoch,trainedsamples,allsamples,100*trainedsamples/allsamples))\n",
    "        TrainAccThisEpoch = float(correct_train*100)/SamplePerEpoch #构成百分数所以*100\n",
    "        TrainLossThisEpoch = float(loss_train*100)/SamplePerEpoch #loss太小不便于迭代所以*100\n",
    "        trainlosslist.append(TrainLossThisEpoch)\n",
    "        net.eval()\n",
    "        correct_test = 0\n",
    "        loss_test = 0\n",
    "        TestSample = testdata.dataset.__len__()\n",
    "        for x,y in testdata:\n",
    "            y = y.view(x.shape[0])\n",
    "            correct,loss = TestOnce(net,criterion,x,y)\n",
    "            #计算总的correct与loss\n",
    "            correct_test += correct\n",
    "            loss_test += loss\n",
    "        TestAccThisEpoch = float(correct_test*100)/TestSample\n",
    "        TestLossThisEpoch = float(loss_test*100)/TestSample\n",
    "        testlosslist.append(TestLossThisEpoch)\n",
    "        print(\"\\t Train Loss:{:.6f}, Test Loss:{:.6f}, Train Acc:{:.3f}%, TestAcc:{:.3f}%\".format(TrainLossThisEpoch, TestLossThisEpoch, TrainAccThisEpoch,TestAccThisEpoch))\n",
    "        if (highestacc == None) or (highestacc < TestAccThisEpoch):\n",
    "            highestacc = TestAccThisEpoch\n",
    "            torch.save(net.state_dict(),os.path.join(PATH,modelname+\".pt\"))\n",
    "            print(\"\\t Weights Saved\")\n",
    "            \n",
    "        early_stop = early_stopping(TestLossThisEpoch)\n",
    "        if early_stop == True:\n",
    "            break\n",
    "        print(\"【DONE】\")\n",
    "        return trainlosslist, testlosslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_procedure(net,epochs,bs,modelname,PATH,lr=0.001,alpha=0.99,gamma=0,tol=10**(-5),wd=0):\n",
    "    torch.manual_seed(1412)\n",
    "    #分割数据，设置num_workers会延长GPU的等待速度因此一般在GPU状态下不设置\n",
    "    batchdata = DataLoader(train,batch_size=bs,shuffle=True\n",
    "    ,drop_last=False, num_workers=4, pin_memory=True)\n",
    "    testdata = DataLoader(test,batch_size=bs,shuffle=False #测试集上不进行shuffle，可以加速运算\n",
    "    ,drop_last=False, num_workers=4, pin_memory=True)\n",
    "    #损失函数，优化算法\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    opt =optim.RMSprop(net.parameters(),lr=lr,alpha=alpha,momentum=gamma,weight_decay=wd)\n",
    "    #训练\n",
    "    trainloss, testloss =fit_test(net,batchdata,testdata,criterion,opt,epochs,tol,modelname,PATH)\n",
    "    return trainloss, testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotloss(trainloss, testloss):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(trainloss, color=\"red\", label=\"Trainloss\")\n",
    "    plt.plot(testloss, color=\"orange\", label=\"Testloss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"D:\\study\\ML\\kaggle\\SVHN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgtime = []\n",
    "for i in range(5):\n",
    "    torch.manual_seed(1412)\n",
    "    resnet18_ = m.resnet18()\n",
    "    net = MyResNet().to(device,non_blocking=True)\n",
    "    start = time() #计算训练时间\n",
    "    trainloss, testloss = full_procedure(net,epochs=3, bs=256\n",
    "                            ,modelname=\"model_seletion_resnet\"\n",
    "                            ,PATH = PATH)\n",
    "    avgtime.append(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgtime = []\n",
    "for i in range(5):\n",
    "        torch.manual_seed(1412)\n",
    "        vgg16_ = m.vgg16_bn()\n",
    "        net = MyVgg().to(device,non_blocking=True)\n",
    "        start = time() #计算训练时间\n",
    "        #此时使用的是full_procedure的默认参数\n",
    "        trainloss, testloss = full_procedure(net,epochs=3, bs=256\n",
    "        ,modelname=\"model_seletion_vgg\"\n",
    "        ,PATH = PATH)\n",
    "        avgtime.append(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"D:\\study\\ML\\kaggle\\SVHN\\models\\ConfirmedResNet\"\n",
    "modelname = \"myResNet_test0\"\n",
    "print(modelname)\n",
    "torch.manual_seed(1412)\n",
    "resnet18_ = m.resnet18()\n",
    "net = MyResNet().to(device,non_blocking=True)\n",
    "start = time() #计算训练时间\n",
    "trainloss, testloss = full_procedure(net,epochs=10, bs=256\n",
    "        ,modelname=modelname\n",
    "        ,PATH = PATH)\n",
    "print(time()-start)\n",
    "plotloss(trainloss,testloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_.layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
